{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.profiler\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset import MyDataset\n",
    "from dataloader import PatchDataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from model import CNN\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log_dir = \"model_v15_logs/results\"\n",
    "writer = SummaryWriter(log_dir=save_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, checkpoint, filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(loss, psnr, ssim, epoch):\n",
    "    \n",
    "    writer.add_scalar(\"Train Loss\", loss, epoch)\n",
    "    writer.add_scalar(\"PSNR/Epoch\", psnr, epoch)\n",
    "    writer.add_scalar(\"SSIM/Epoch\", ssim, epoch)\n",
    "    \n",
    "    del psnr, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(image, model):\n",
    "    no_of_layers= 0\n",
    "    layers = []\n",
    "    weights = []\n",
    "    outputs = []\n",
    "    processed = []\n",
    "    names = []\n",
    "    type_list = [nn.Conv2d, nn.AvgPool2d, nn.ConvTranspose2d, nn.Upsample]\n",
    "    model_children=list(model.children())\n",
    "\n",
    "    for child in model_children:\n",
    "        if type(child) in type_list:\n",
    "            no_of_layers+=1\n",
    "            layers.append(child)\n",
    "            if type(child)==nn.Conv2d:\n",
    "                weights.append(child.weight)\n",
    "\n",
    "    for layer in layers[0:]:\n",
    "        image = layer(image)\n",
    "        outputs.append(image)\n",
    "\n",
    "    for feature_map in outputs:\n",
    "        feature_map = feature_map.squeeze(0)\n",
    "        gray_scale = torch.sum(feature_map,0)\n",
    "        gray_scale = gray_scale / feature_map.shape[0]\n",
    "        #for gray_scale in feature_map:\n",
    "        processed.append(gray_scale.detach().cpu().numpy())\n",
    "        names.append(str(gray_scale.shape))\n",
    "        \n",
    "    fig = plt.figure(figsize=(20, 700))\n",
    "    for i in range(len(processed)):\n",
    "        a = fig.add_subplot(1000, 10, i+1)\n",
    "        imgplot = plt.imshow(processed[i], cmap=\"gray\")\n",
    "        a.axis(\"on\")\n",
    "        a.set_title(names[i], fontsize=8)\n",
    "    plt.savefig(str(f'{save_log_dir}/feature_maps.jpg'), bbox_inches='tight')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =transforms.Compose([transforms.ToTensor()])\n",
    "dataset = MyDataset(\"image\")\n",
    "loader = PatchDataLoader(dataset=dataset, transform=transform, kernel_size=64, stride=64, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(loader)\n",
    "images = next(dataiter)\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('First batch input image.', img_grid)\n",
    "del img_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.to(\"cuda\")\n",
    "model.train()\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "writer.add_graph(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "summary = { \n",
    "        \"BSIZE\": loader.batch_size,\n",
    "        \"EPOCH\": epochs, \n",
    "        \"LFUNC\": criterion, \n",
    "        \"OPTIM\": optimizer,\n",
    "        \"SIZE\" : loader.size,\n",
    "        \"STRIDE\": loader.stride,\n",
    "        \"BOTTLENECK\": model.bottleneck[2],\n",
    "        \"RELU\": model.encoder[1],\n",
    "        \"DOWNSAMPLE\": model.encoder[2],\n",
    "        \"UPSAMPLE\": model.decoder[2]\n",
    "        }\n",
    "\n",
    "writer.add_text(\"Summary\", str(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with torch.profiler.profile(\n",
    "        schedule=torch.profiler.schedule(wait=10, warmup=10, active=2, repeat=0),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(save_log_dir),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof: \"\"\"\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, inputs in enumerate(loader,0):\n",
    "        if inputs == None:\n",
    "            break\n",
    "        \n",
    "        input = inputs.to(\"cuda\")\n",
    "        output = model(input)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, input)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            img_grid = torchvision.utils.make_grid(output)\n",
    "            writer.add_image('First batch output image.', img_grid, global_step=epoch)\n",
    "            del img_grid  \n",
    "            \n",
    "    save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, save_log_dir)\n",
    "\n",
    "    psnr_val = psnr(input[0].transpose(0,2).detach().cpu().numpy(), output[0].transpose(0,2).detach().cpu().numpy()) #psnr(input[0], output[0], max_val=1.)\n",
    "    ssim_val = ssim(input[0].transpose(0,2).detach().cpu().numpy(), output[0].transpose(0,2).detach().cpu().numpy(), channel_axis=2)\n",
    "    print(f\"Epoch: {epoch}/{epochs}, Loss: {loss}, PSNR: {psnr_val}, SSIM: {ssim_val}\")\n",
    "    draw_graph(loss=loss, psnr=psnr_val, ssim=ssim_val, epoch=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deeplr_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5840b43f9bc7282ec1cc6c927bf00c2cd9a7d7a57a2901581002cd6c7fc6eab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
